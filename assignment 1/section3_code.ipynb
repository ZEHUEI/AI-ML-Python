{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5008ca2",
   "metadata": {},
   "source": [
    "Section 3 Part 1 code with comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf70101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('40443486_features.csv')\n",
    "\n",
    "# Step 2: Create a histogram using Matplotlib\n",
    "plt.hist(data['nr_pix'], bins=20, color='pink', edgecolor='black', density=True)\n",
    "\n",
    "# Step 3: Add a KDE curve\n",
    "kde = gaussian_kde(data['nr_pix'])\n",
    "x_values = np.linspace(data['nr_pix'].min(), data['nr_pix'].max(), 1000)\n",
    "plt.plot(x_values, kde(x_values), color='red', label='KDE')\n",
    "\n",
    "# Step 4: Add labels and title\n",
    "plt.title('Distribution of nr_pix')\n",
    "plt.xlabel('Number of Black Pixels (nr_pix)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef727be",
   "metadata": {},
   "source": [
    "Section 3 Part 2 code with comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('40443486_features.csv')\n",
    "\n",
    "# Step 2: Separate the data into letters and non-letters\n",
    "letters = data[data['image_label'].isin(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])]\n",
    "non_letters = data[~data['image_label'].isin(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])]\n",
    "\n",
    "# Step 3: Calculate summary statistics for letters and non-letters\n",
    "letters_summary = letters.describe().loc[['mean', '50%', 'std']]\n",
    "non_letters_summary = non_letters.describe().loc[['mean', '50%', 'std']]\n",
    "\n",
    "# Rename the rows for clarity\n",
    "letters_summary.rename(index={'50%': 'median'}, inplace=True)\n",
    "non_letters_summary.rename(index={'50%': 'median'}, inplace=True)\n",
    "\n",
    "# Step 4: Display the summary statistics for all features\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(\"Summary Statistics for Letters:\")\n",
    "print(letters_summary)\n",
    "\n",
    "print(\"\\nSummary Statistics for Non-Letters:\")\n",
    "print(non_letters_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a43c6",
   "metadata": {},
   "source": [
    "Section 3 Part 3 code with comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9def3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('40443486_features.csv')\n",
    "\n",
    "# Separate the data into letters and non-letters\n",
    "letters = data[data['image_label'].isin(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])]\n",
    "non_letters = data[data['image_label'].isin(['sad', 'smiley', 'xclaim'])]\n",
    "\n",
    "# Perform the t-test\n",
    "t_stat, p_value = stats.ttest_ind(letters['custom'], non_letters['custom'])\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Determine significance\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a2b96",
   "metadata": {},
   "source": [
    "Section 3 Part 4 code with comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"40443486_features.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic info and first few rows\n",
    "df.info(), df.head()\n",
    "\n",
    "\n",
    "# Drop non-numeric columns\n",
    "numeric_df = df.drop(columns=[\"image_label\", \"index\"])\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Extract correlation pairs and sort\n",
    "correlation_unstacked = correlation_matrix.unstack()\n",
    "sorted_correlations = correlation_unstacked.abs().sort_values(ascending=False)\n",
    "\n",
    "# Remove self-correlations\n",
    "sorted_correlations = sorted_correlations[sorted_correlations < 1].drop_duplicates()\n",
    "\n",
    "# Display top correlated feature pairs\n",
    "top_correlations = sorted_correlations.head(10)\n",
    "top_correlations"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
